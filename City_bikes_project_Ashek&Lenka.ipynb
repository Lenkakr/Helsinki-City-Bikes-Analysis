{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helsinki City Bikes data analysis, challenge - using numpy only\n",
    "\n",
    "\n",
    "<img src=\"cover.png\">\n",
    "\n",
    "\n",
    "We'll be using the Helsinki City Bikes data (available [here](https://www.hsl.fi/en/opendata)) for our Numpy analysis. The data is covering the whole period from April to October 2019 and can be downloaded monthly. More general information about Helsinki City Bikes project can be found [here](https://kaupunkipyorat.hsl.fi/en).\n",
    "\n",
    "The data cover details of all the bike rides. It covers date of the departure date,\treturn date, departure station id,\tdeparture station name,\treturn station id, return station name,\tcovered distance (m), duration (sec.).\n",
    "\n",
    "Before the loading of the CSV data, we need to rename two stations that have comma in their name (to prevent errors caused by the different number of columns). We changed the commas inside the name of these stations to semicommas in all our files. Another thing we have to be aware of is that Finnish characters are not part of the typical encoding range, thus if we need to use encoding UTF-8 (8-bit Unicode Transformation Format) to have all the station names displayed correctly.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-20T08:05:23.696527Z",
     "start_time": "2020-05-20T08:04:36.908005Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(450056, 8)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([['2019-09-30T23:59:29', '2019-10-01T00:10:02', '7', 'Designmuseo',\n",
       "        '64', 'Tyynenmerenkatu', '2250', '628'],\n",
       "       ['2019-09-30T23:59:11', '2019-10-01T00:07:37', '111',\n",
       "        'Esterinportti', '86', 'Kuusitie', '1749', '501'],\n",
       "       ['2019-09-30T23:54:58', '2019-09-30T23:59:22', '161',\n",
       "        'Eteläesplanadi', '24', 'Mannerheimintie', '535', '260'],\n",
       "       ['2019-09-30T23:51:09', '2019-09-30T23:58:59', '517',\n",
       "        'Länsituuli', '900', 'Orionintie', '2140', '466'],\n",
       "       ['2019-09-30T23:50:09', '2019-10-01T00:13:52', '115',\n",
       "        'Venttiilikuja', '12', 'Kanavaranta', '4792', '1422']],\n",
       "      dtype='<U37')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "# april_data = np.genfromtxt('2019-04.csv', delimiter=\",\" , encoding='utf-8',\n",
    "#                            dtype=[('<U18'),('<U18'),('int64'),('<U18'),('int64'),('<U18'),('int64'),('int64')], skip_header=1)\n",
    "# may_data = np.genfromtxt('2019-05.csv', delimiter=\",\" , encoding='utf-8',\n",
    "#                            dtype=[('<U18'),('<U18'),('int64'),('<U18'),('int64'),('<U18'),('int64'),('int64')], skip_header=1)\n",
    "# june_data = np.genfromtxt('2019-06.csv', delimiter=\",\" , encoding='utf-8',\n",
    "#                            dtype=[('<U18'),('<U18'),('int64'),('<U18'),('int64'),('<U18'),('int64'),('int64')], skip_header=1)\n",
    "# july_data = np.genfromtxt('2019-07.csv', delimiter=\",\" , encoding='utf-8',\n",
    "#                            dtype=[('<U18'),('<U18'),('int64'),('<U18'),('int64'),('<U18'),('int64'),('int64')], skip_header=1)\n",
    "# august_data = np.genfromtxt('2019-08.csv', delimiter=\",\" , encoding='utf-8',\n",
    "#                            dtype=[('<U18'),('<U18'),('int64'),('<U18'),('int64'),('<U18'),('int64'),('int64')], skip_header=1)\n",
    "# september_data = np.genfromtxt('2019-09.csv', delimiter=\",\" , encoding='utf-8',\n",
    "#                            dtype=[('<U18'),('<U18'),('int64'),('<U18'),('int64'),('<U18'),('int64'),('int64')], skip_header=1)\n",
    "# november_data = np.genfromtxt('2019-10.csv', delimiter=\",\" , encoding='utf-8',\n",
    "#                            dtype=[('<U18'),('<U18'),('int64'),('<U18'),('int64'),('<U18'),('int64'),('int64')], skip_header=1)\n",
    "\n",
    "april_data = np.genfromtxt('2019-04.csv', delimiter=\",\" , encoding='utf-8',dtype='str', skip_header=1)\n",
    "may_data = np.genfromtxt('2019-05.csv', delimiter=\",\" , encoding='utf-8', dtype='str', skip_header=1)\n",
    "june_data = np.genfromtxt('2019-06.csv', delimiter=\",\" , encoding='utf-8',dtype='str', skip_header=1)\n",
    "july_data = np.genfromtxt('2019-07.csv', delimiter=\",\" , encoding='utf-8', dtype='str', skip_header=1)\n",
    "august_data = np.genfromtxt('2019-08.csv', delimiter=\",\" , encoding='utf-8',dtype='str', skip_header=1)\n",
    "september_data = np.genfromtxt('2019-09.csv', delimiter=\",\" , encoding='utf-8',dtype='str', skip_header=1)\n",
    "october_data = np.genfromtxt('2019-10.csv', delimiter=\",\" , encoding='utf-8',dtype='str', skip_header=1)\n",
    "print(september_data.shape)\n",
    "september_data[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're reading all of our data as string dtype, as we want to combine them in the next step (if we choose to have different dtype in each column, we will lose one dimension).\n",
    "\n",
    "After that we'll stack all of our monthly datasets vertically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-20T08:09:55.354951Z",
     "start_time": "2020-05-20T08:09:09.205791Z"
    }
   },
   "outputs": [],
   "source": [
    "final_data = np.vstack((april_data,may_data,june_data,july_data,august_data,september_data,october_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-20T08:09:59.253533Z",
     "start_time": "2020-05-20T08:09:59.237577Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class:  ndarray\n",
      "shape:  (3787948, 8)\n",
      "strides:  (1184, 148)\n",
      "itemsize:  148\n",
      "aligned:  True\n",
      "contiguous:  True\n",
      "fortran:  False\n",
      "data pointer: 0x199d9b3c040\n",
      "byteorder:  little\n",
      "byteswap:  False\n",
      "type: <U37\n"
     ]
    }
   ],
   "source": [
    "np.info(final_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our final data has two dimensions and shape (3787948, 8).\n",
    "\n",
    "Next we will check for missing values. As the data is tracked for all the trips, even those that are of 0 meter distance, it's expected, that we won't have any missing values, but will have to deal with some invalid inputs instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-20T08:10:13.427499Z",
     "start_time": "2020-05-20T08:10:03.349110Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([], dtype=int64), array([], dtype=int64))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(final_data=='nan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-20T08:10:14.807525Z",
     "start_time": "2020-05-20T08:10:13.718826Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([], dtype=int64), array([], dtype=int64))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(final_data==' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.isnan(final_data).any"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As predicted, no missing values detected, both as 'nan' or as ' ' (empty space) in the string of our values. We now should check for the possible invalid inputs in our data.\n",
    "\n",
    "Further in this analysis we're going to work either with string data or numerical data (with distance and time of the rides). Thus we will create dataset with only numerical values and will combine two datasets in our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-20T08:10:18.096753Z",
     "start_time": "2020-05-20T08:10:18.088775Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3787948, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([['2', '57'],\n",
       "       ['2196', '569'],\n",
       "       ['0', '20'],\n",
       "       ['2121', '596'],\n",
       "       ['2460', '1127']], dtype='<U37')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#looking at the data, we have array of lists\n",
    "dst_time = final_data[:,-2:]\n",
    "print(dst_time.shape)\n",
    "dst_time[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to convert our data from string type to integer. In the process we had to first convert to floats (as there were inputs that had decimal values) and then convert to integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-20T08:10:26.993045Z",
     "start_time": "2020-05-20T08:10:21.883591Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2., 57.])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#first to the float64\n",
    "dst_time = dst_time[:][:].astype('float64')\n",
    "dst_time[0]  ## array of list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-20T08:10:27.325665Z",
     "start_time": "2020-05-20T08:10:27.265318Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2, 57], dtype=int64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#then to the integer\n",
    "dst_time = dst_time[:][:].astype('int64')\n",
    "dst_time[0]  ## array of list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Possible work with the data\n",
    "\n",
    "1) DATA Screenig and specifying the invalid inputs\n",
    "   - returing to same stations (with ride time less than 60 seconds)\n",
    "   - checking the min max of the distance and time\n",
    "   - frequency bike malfunctions (too short rides, too long rides, problem with mobile apps internet)\n",
    "   \n",
    "2) DATA Analysis\n",
    "   - Total distance covered over the period and std deviation\n",
    "   - Total hours cycled over the period and std deviation\n",
    "   - Average number of rides by months\n",
    "   - Correlation between distance and time\n",
    "   - The diffences between months according to the ride distance and time\n",
    "   - Most populer departure and return stations\n",
    "   - Finding the busiest hours in the day time\n",
    "   - Most frequent rutes used\n",
    "   - Normalizing the data\n",
    "   - Moving average"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking those rides that returned the bike to the same station\n",
    "\n",
    "As this could be due to some malfunction, mobile app error or mistake. If the person just borrowed the bike for couple seconds and returned it, it could negatively effect our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-20T08:10:34.246483Z",
     "start_time": "2020-05-20T08:10:34.016102Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([      0,       2,      15, ..., 3787911, 3787918, 3787919],\n",
       "       dtype=int64),)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking for indexes of those rides\n",
    "same_stations_inds = np.where(final_data[:,3] == final_data[:,5])\n",
    "same_stations_inds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-20T08:10:38.116503Z",
     "start_time": "2020-05-20T08:10:38.079600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The number of rides with same departure and return station 228,383. \n",
      "\n",
      "Percentage of rides from same station rides is 6.03% from the whole dataset.\n"
     ]
    }
   ],
   "source": [
    "#finding total number of those rides\n",
    "uniquevalues,same_stations_totals = np.unique(same_stations_inds, return_counts=True)\n",
    "same_stations_totals = same_stations_totals.sum()\n",
    "print('\\nThe number of rides with same departure and return station {:,}.'.format(same_stations_totals),'\\n')\n",
    "print('Percentage of rides from same station rides is {:.2f}% from the whole dataset.'.format(same_stations_totals/(len(final_data))*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In total there were 228,383 rides that returned the bike to the same station. But that doesn't mean that it was invalid ride right away, therefore we need to check the times of these rides.\n",
    "\n",
    "What we would consider invalid ride would be if someone borrowed the bike and returned it withing 60 seconds to the same station."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-20T08:10:43.101754Z",
     "start_time": "2020-05-20T08:10:43.074785Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The total number of invalid rides is 112,474. \n",
      "\n",
      "Percentage of invalid rides from those with same departure and return station rides is 49.25%, which is 2.97% of all rides.\n"
     ]
    }
   ],
   "source": [
    "invalid_rides_ind = np.where(dst_time[same_stations_inds,1]<= 60)\n",
    "inv_values, total_inv_rides = np.unique(invalid_rides_ind[1], return_counts=True)\n",
    "total_inv_rides = total_inv_rides.sum()\n",
    "print('\\nThe total number of invalid rides is {:,}.'.format(total_inv_rides),'\\n')\n",
    "print('Percentage of invalid rides from those with same departure and return station rides is {:.2f}%, which is {:.2f}% of all rides.'.format(total_inv_rides/same_stations_totals*100,total_inv_rides/(len(final_data))*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the total number of invalid rides, meaning those that started and finished in the same station and lasted less than 60 second, was 112,474, which was 49.25% of all the rides that had same departure and return station.\n",
    "\n",
    "We want to remove these rides from our final data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-20T08:10:52.227606Z",
     "start_time": "2020-05-20T08:10:49.284756Z"
    }
   },
   "outputs": [],
   "source": [
    "last_col = final_data[:,7]\n",
    "last_col = last_col.astype('float64')\n",
    "last_col = last_col.astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-20T08:10:54.540362Z",
     "start_time": "2020-05-20T08:10:54.494447Z"
    }
   },
   "outputs": [],
   "source": [
    "temp_inds = np.where(last_col <= 60)\n",
    "common_elements = np.intersect1d(same_stations_inds[0],temp_inds)\n",
    "\n",
    "#final_data1 = np.delete(final_data[:],common_emelments,axis=1) for some reason didnt work??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-20T07:43:39.553119Z",
     "start_time": "2020-05-20T07:42:59.456394Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3675474, 8)\n",
      "[['2019-04-30T23:59:31' '2019-05-01T00:09:00' '140' 'Verkatehtaanpuisto'\n",
      "  '134' 'Haukilahdenkatu' '2196' '569']\n",
      " ['2019-04-30T23:59:21' '2019-05-01T00:09:20' '39' 'Ooppera' '44'\n",
      "  'Sörnäisten metroasema' '2121' '596']\n",
      " ['2019-04-30T23:59:19' '2019-05-01T00:18:12' '57'\n",
      "  'Lauttasaaren ostoskeskus' '63' 'Jätkäsaarenlaituri' '2460' '1127']\n",
      " ['2019-04-30T23:59:19' '2019-05-01T00:16:32' '505' 'Westendinasema'\n",
      "  '593' 'Toppelundintie' '2058' '1028']\n",
      " ['2019-04-30T23:59:14' '2019-05-01T00:06:15' '647' 'Lystimäki' '623'\n",
      "  'Nelikkotie' '1429' '416']\n",
      " ['2019-04-30T23:59:13' '2019-05-01T00:14:11' '36' 'Apollonkatu' '120'\n",
      "  'Mäkelänkatu' '3413' '898']\n",
      " ['2019-04-30T23:59:09' '2019-05-01T00:07:16' '225' 'Maunula' '230'\n",
      "  'Mäkitorpantie' '1882' '483']\n",
      " ['2019-04-30T23:59:04' '2019-05-01T00:06:34' '12' 'Kanavaranta' '22'\n",
      "  'Rautatientori / länsi' '1217' '444']\n",
      " ['2019-04-30T23:59:01' '2019-05-01T00:03:28' '647' 'Lystimäki' '581'\n",
      "  'Niittykumpu (M)' '1180' '266']\n",
      " ['2019-04-30T23:58:48' '2019-05-01T00:05:12' '729' 'Leppävaaranaukio'\n",
      "  '707' 'Majurinkulma' '1316' '382']]\n"
     ]
    }
   ],
   "source": [
    "arr = np.arange(len(final_data))\n",
    "#np.setdiff1d(arr,common_emelments)\n",
    "final_data = final_data[np.setdiff1d(arr,common_elements)]\n",
    "print(final_data.shape)\n",
    "print(final_data[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we already removed those rides, that were invalid cause they were not really rides, we should also have a look into those rides, that were way too long, so could cause some problems in calculation of our descriptive analysis.\n",
    "\n",
    "Let's look at the longest rides distance-wise.\n",
    "\n",
    "### Removing too long rides (distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-20T08:11:09.890802Z",
     "start_time": "2020-05-20T08:11:06.698494Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  69405.     69908.33   74425.     83175.    118841.67  122115.\n",
      "  129742.    157656.    163633.33  190216.67  241519.    347575.\n",
      "  407383.33  421708.33  433104.    556125.    951100.   1004058.33\n",
      " 2106675.   3589426.  ]\n"
     ]
    }
   ],
   "source": [
    "len_col = final_data[:,6]\n",
    "len_col = len_col.astype('float64')\n",
    "sort_len = np.argsort(len_col) # giving us the indexes\n",
    "print(len_col[sort_len[-20:]])#printing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These rides were rather long for the 30 minutes limit that is set for use of the City Bikes (within this time you have to return the bike to the station, otherwise you have to pay for exceeding the time). Nevertheless, we believe that rides within 200km are possible, even though they will end up being quite pricey. We decided to remove longest 10 rides, because they were over 240km long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-20T08:11:38.418904Z",
     "start_time": "2020-05-20T08:11:13.118761Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3787938, 8)\n",
      "[['2019-04-30T23:59:35' '2019-05-01T00:00:36' '43' 'Karhupuisto' '43'\n",
      "  'Karhupuisto' '2' '57']\n",
      " ['2019-04-30T23:59:31' '2019-05-01T00:09:00' '140' 'Verkatehtaanpuisto'\n",
      "  '134' 'Haukilahdenkatu' '2196' '569']\n",
      " ['2019-04-30T23:59:25' '2019-04-30T23:59:46' '121' 'Vilhonvuorenkatu'\n",
      "  '121' 'Vilhonvuorenkatu' '0' '20']\n",
      " ['2019-04-30T23:59:21' '2019-05-01T00:09:20' '39' 'Ooppera' '44'\n",
      "  'Sörnäisten metroasema' '2121' '596']\n",
      " ['2019-04-30T23:59:19' '2019-05-01T00:18:12' '57'\n",
      "  'Lauttasaaren ostoskeskus' '63' 'Jätkäsaarenlaituri' '2460' '1127']]\n"
     ]
    }
   ],
   "source": [
    "#removing longest 10 rides from the dataset\n",
    "longest = sort_len[-10:]\n",
    "arr1 = np.arange(len(final_data))\n",
    "#np.setdiff1d(arr,common_emelments)\n",
    "final_data = final_data[np.setdiff1d(arr1,longest)]\n",
    "print(final_data.shape)\n",
    "print(final_data[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing too short rides (distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-20T08:12:04.895515Z",
     "start_time": "2020-05-20T08:11:44.467824Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100235\n"
     ]
    }
   ],
   "source": [
    "#final_data[final_data[:,6].astype('float')<0]=0\n",
    "\n",
    "len_col = final_data[:,6]\n",
    "len_col = len_col.astype('float64')\n",
    "sort_len2 = np.argsort(len_col)\n",
    "#print(len_col[sort_len[:10]]) #printing values of the first 10 - to assess the values\n",
    "#print(np.where(len_col == -4290436)[0]) \n",
    "too_short = np.where(len_col<= 0)\n",
    "\n",
    "#print(too_short[0][:3447982])\n",
    "#getting those values <=0 from len_col\n",
    "too_short1 = list(too_short[0])\n",
    "print(len(too_short1))\n",
    "#too_short1[:5]\n",
    "#print(sort_len2[:37768])\n",
    "#final_data1 = np.delete(final_data[:],common_emelments,axis=1) for some reason didnt work??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that some rides were still with distance of 0 meter, even though already removed those starting and finishing in the same station within one minute lenght. This is visibly another kind of invalid ride, thus we will removed all those with distance of 0 meters as well, including the strange ride with negative distance. \n",
    "\n",
    "Let's remove the rides that are shorter than 5 meters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-20T08:28:22.191301Z",
     "start_time": "2020-05-20T08:27:33.049740Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3653803, 8)\n"
     ]
    }
   ],
   "source": [
    "#removing too short rides from data\n",
    "#final_data[final_data[:,6].astype('float')<0]=0\n",
    "#shortest = sort_len[:37768]\n",
    "#arr2 = np.arange(len(final_data))\n",
    "#len(np.setdiff1d(arr2,shortest))\n",
    "#final_data = final_data[np.setdiff1d(arr2,shortest)]\n",
    "final_data = final_data[final_data[:,6].astype(\"float\")>5] ##distance limit\n",
    "print(final_data.shape)\n",
    "#print(final_data[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-20T08:28:26.617722Z",
     "start_time": "2020-05-20T08:28:26.612738Z"
    }
   },
   "source": [
    "### Removing too short rides (time)\n",
    "\n",
    "Even though we removed the rides that have the same departure and return station and are shorter than 1 minute, we still have some rides that last are of very short time, 0 seconds included. We decided to removed those, those rides, that lasted less than 10 seconds from our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-20T08:28:51.415141Z",
     "start_time": "2020-05-20T08:28:28.662673Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3653803, 8)\n"
     ]
    }
   ],
   "source": [
    "final_data = final_data[final_data[:,7].astype(\"float\")>10] #time limit\n",
    "print(final_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-20T08:13:29.201949Z",
     "start_time": "2020-05-20T08:13:27.101974Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2' '2196' '2121' ... '3477' '3531' '1468']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([], dtype=int64),)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking for our negative distance, which is no longer there\n",
    "#print(final_data[:,6])\n",
    "#np.where(final_data[:,6] == '-4290436')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-20T08:29:55.900975Z",
     "start_time": "2020-05-20T08:29:55.896195Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of rides in our final dataset is 3,653,803.\n"
     ]
    }
   ],
   "source": [
    "#final number of rows\n",
    "print('\\nNumber of rides in our final dataset is {:,}.'.format(len(final_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data analysis\n",
    "\n",
    "Covering the basic descriptive analysis of all the valid rides."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-20T08:30:25.330488Z",
     "start_time": "2020-05-20T08:30:16.368210Z"
    }
   },
   "outputs": [],
   "source": [
    "#setting up the time column\n",
    "time_col = final_data[:,7]\n",
    "time_col = time_col.astype('float64')\n",
    "time_col = time_col.astype('int64')\n",
    "\n",
    "#setting up the distance column\n",
    "dist_col = final_data[:,6]\n",
    "dist_col = dist_col.astype('float64')\n",
    "dist_col = dist_col.astype('int64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distance of rides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-20T08:30:28.914238Z",
     "start_time": "2020-05-20T08:30:28.898281Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total distance covered by all the rides was 7,890,152 km.\n"
     ]
    }
   ],
   "source": [
    "#total distance over the whole period\n",
    "total_distance = np.sum(dist_col)/1000\n",
    "print('\\nTotal distance covered by all the rides was {:,.0f} km.'.format(total_distance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-20T08:30:34.304125Z",
     "start_time": "2020-05-20T08:30:34.292157Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20.525889547346512"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tothemoon = total_distance/384400\n",
    "tothemoon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### To the Moon and back over 10 times!\n",
    "It looks like people cycled a lot with Helsinki City Bikes, but this number seem rather big to give us a concrete idea. The distance from the Earth to the Moon is 384,400km. So withing 7 months, people in Helsinki can cycle to the Moon and back more than 10 times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-20T08:31:01.945694Z",
     "start_time": "2020-05-20T08:31:01.924031Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "People on average rode 2.16 km per ride.\n"
     ]
    }
   ],
   "source": [
    "#average bike ride\n",
    "average_dist = np.average(dist_col)/1000\n",
    "print('\\nPeople on average rode {:.2f} km per ride.'.format(average_dist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-20T08:31:07.681648Z",
     "start_time": "2020-05-20T08:31:07.622802Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "std: 1.64 km\n"
     ]
    }
   ],
   "source": [
    "#Standard deviation distance\n",
    "std_dist = np.std(dist_col)/1000\n",
    "print('std: {:.2f} km'.format(std_dist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-20T08:31:17.178674Z",
     "start_time": "2020-05-20T08:31:17.168700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The longest valid ride was 190.22 km long.\n"
     ]
    }
   ],
   "source": [
    "#longest bike ride\n",
    "longest_dist = np.max(dist_col)/1000\n",
    "print('\\nThe longest valid ride was {:,.2f} km long.'.format(longest_dist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-20T08:31:23.150503Z",
     "start_time": "2020-05-20T08:31:23.139487Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The shortest valid ride was 6.00 m long.\n"
     ]
    }
   ],
   "source": [
    "#the shortest distance\n",
    "shortest_dist = np.min(dist_col)\n",
    "print('\\nThe shortest valid ride was {:.2f} m long.'.format(shortest_dist))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time of rides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-20T08:31:39.808758Z",
     "start_time": "2020-05-20T08:31:39.794795Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum time of one single ride: 62.52 day\n"
     ]
    }
   ],
   "source": [
    "max_time = (np.max(time_col)/3600)/24\n",
    "print('Maximum time of one single ride: {:.2f} day'.format(max_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-20T08:31:52.106499Z",
     "start_time": "2020-05-20T08:31:52.097138Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum time of one single ride: 0.2 min\n"
     ]
    }
   ],
   "source": [
    "min_time = np.min(time_col)/60\n",
    "print('Minimum time of one single ride: {} min'.format(min_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-20T08:32:29.372681Z",
     "start_time": "2020-05-20T08:32:29.357722Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average time:15.83 min\n"
     ]
    }
   ],
   "source": [
    "#average ride time\n",
    "average_time = np.average(time_col)/60\n",
    "print('\\nAverage time:{:.2f} min'.format(average_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-20T08:32:35.047934Z",
     "start_time": "2020-05-20T08:32:34.996072Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "std: 136.32 min\n"
     ]
    }
   ],
   "source": [
    "#Standard deviation time\n",
    "std_time = np.std(time_col)/60\n",
    "print('std: {:,.2f} min'.format(std_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Is there correlation between time and distance of the rides..?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-20T08:32:41.787902Z",
     "start_time": "2020-05-20T08:32:41.624338Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.09738007]\n",
      " [0.09738007 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "correlation = np.corrcoef(dist_col,time_col)\n",
    "print(correlation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though the correlation between distance and time of the rides would seem rather intuitive, we can see that there was no relationship bewteen these two variables. Seems like some people managed to bike longer distance in longer time, but some were just going slowly and enjoyed the city."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Most popular departure and return stations\n",
    "\n",
    "What stations were used the most and which the least?\n",
    "\n",
    "<img src=\"map.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Most popular departure station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-20T08:32:56.858308Z",
     "start_time": "2020-05-20T08:32:53.018212Z"
    }
   },
   "outputs": [],
   "source": [
    "# Popular Departure stations\n",
    "(popular_dep_st,popular_dep_count) = np.unique(final_data[:,3],return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-20T08:32:59.075803Z",
     "start_time": "2020-05-20T08:32:59.068822Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Töölönlahdenkatu\n",
      "81984\n"
     ]
    }
   ],
   "source": [
    "max_index_row = np.argmax(popular_dep_count)\n",
    "print(popular_dep_st[max_index_row])\n",
    "print(popular_dep_count[max_index_row])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Most popular return station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-20T08:33:06.700786Z",
     "start_time": "2020-05-20T08:33:02.010068Z"
    }
   },
   "outputs": [],
   "source": [
    "# Popular Returned stations\n",
    "(popular_ret_st, popular_ret_count) = np.unique(final_data[:,5],return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-20T08:33:08.767351Z",
     "start_time": "2020-05-20T08:33:08.758380Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Töölönlahdenkatu\n",
      "81811\n"
     ]
    }
   ],
   "source": [
    "max_index_row = np.argmax(popular_ret_count)\n",
    "print(popular_ret_st[max_index_row])\n",
    "print(popular_ret_count[max_index_row])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The least popular departure station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-20T08:33:12.847842Z",
     "start_time": "2020-05-20T08:33:12.838865Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ruomelantie***\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# Least departure stations\n",
    "min_index_row = np.argmin(popular_dep_count)\n",
    "print(popular_dep_st[min_index_row])\n",
    "print(popular_dep_count[min_index_row])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The least popular return station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-20T08:33:15.063766Z",
     "start_time": "2020-05-20T08:33:15.057781Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ruomelantie***\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "# Least returend stations\n",
    "min_index_row = np.argmin(popular_ret_count)\n",
    "print(popular_ret_st[min_index_row])\n",
    "print(popular_ret_count[min_index_row])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
